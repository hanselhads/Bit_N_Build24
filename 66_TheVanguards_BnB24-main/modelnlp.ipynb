{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import fitz\n",
    "import re\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdf(file_path):\n",
    "    doc = fitz.open(file_path)\n",
    "    text = ''\n",
    "    for page in doc:\n",
    "        text += page.get_text()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labels(text):\n",
    "    if re.search(r'education', text, re.IGNORECASE):\n",
    "        return 1\n",
    "    elif re.search(r'experience', text, re.IGNORECASE):\n",
    "        return 2\n",
    "    elif re.search(r'skills', text, re.IGNORECASE):\n",
    "        return 3\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(folder_path):\n",
    "    texts = []\n",
    "    labels = []\n",
    "    for filename in os.listdir(folder_path):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        if os.path.isfile(file_path) and file_path.endswith('.pdf'):\n",
    "            text = extract_text_from_pdf(file_path)\n",
    "            label = get_labels(text)\n",
    "            if label != 0:\n",
    "                texts.append(text)\n",
    "                labels.append(label)\n",
    "    return texts, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_folder = 'data/ALL RESUMES'\n",
    "texts, labels = process_data(pdf_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 13573 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "max_words = 1000\n",
    "tokenizer = Tokenizer(num_words=max_words, oov_token='<OOV>')\n",
    "tokenizer.fit_on_texts(texts)\n",
    "sequences = tokenizer.texts_to_sequences(texts)\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_sequence_length = max(len(seq) for seq in sequences)\n",
    "data = pad_sequences(sequences, maxlen=max_sequence_length)\n",
    "dataset = pd.read_csv('data/ALL RESUMES/ALL-RESUMES.csv')\n",
    "labels = dataset.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert integer labels to one-hot encoded labels\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "le.fit(labels)\n",
    "labels = le.transform(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  0  0  0  0  0  0  0  0  1  1  1  1  1  1  1  1  1  1  2  2  2  2  2\n",
      "  2  2  2  2  2  3  3  3  3  3  3  3  3  3  3  4  4  4  4  4  4  4  4  4\n",
      "  4  5  5  5  5  5  5  5  5  5  5  6  6  6  6  6  6  6  6  6  6  8  8  8\n",
      "  8  8  8  8  8  8  8  7  7  7  7  7  7  7  7  7  7  9  9  9  9  9  9  9\n",
      "  9  9  9 10 10 10 10 10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 12\n",
      " 12 12 12 12 12 12 12 12 12 13 13 13 13 13 13 13 13 13 13 14 14 14 14 14\n",
      " 14 14 14 14 14 15 15 15 15 15 15 15 15 15 15 16 16 16 16 16 16 16 16 16\n",
      " 16 17 17 17 17 17 17 17 17 17 17 19 19 19 19 19 19 19 19 19 19 18 18 18\n",
      " 18 18 18 18 18 18 18 20 20 20 20 20 20 20 20 20 20 21 21 21 21 21 21 21\n",
      " 21 21 21 22 22 22 22 22 22 22 22 22 22 23 23 23 23 23 23 23 23 23 23 24]\n"
     ]
    }
   ],
   "source": [
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 100\n",
    "model = Sequential([\n",
    "    Embedding(max_words, embedding_dim, input_length=max_sequence_length),\n",
    "    LSTM(64),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid')  # 1 unit for binary classification\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_11 (Embedding)    (None, 5166, 100)         100000    \n",
      "                                                                 \n",
      " lstm_11 (LSTM)              (None, 64)                42240     \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 64)                4160      \n",
      "                                                                 \n",
      " dropout_11 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 146465 (572.13 KB)\n",
      "Trainable params: 146465 (572.13 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "6/6 [==============================] - 55s 8s/step - loss: 0.0471 - accuracy: 0.0469 - val_loss: -3.1244 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "6/6 [==============================] - 49s 8s/step - loss: -3.1125 - accuracy: 0.0521 - val_loss: -20.3025 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "6/6 [==============================] - 54s 9s/step - loss: -20.1632 - accuracy: 0.0521 - val_loss: -89.1675 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "6/6 [==============================] - 30s 5s/step - loss: -46.6512 - accuracy: 0.0521 - val_loss: -147.8616 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "6/6 [==============================] - 28s 5s/step - loss: -74.6758 - accuracy: 0.0521 - val_loss: -214.6050 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/10\n",
      "6/6 [==============================] - 27s 5s/step - loss: -101.4772 - accuracy: 0.0521 - val_loss: -293.6375 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/10\n",
      "6/6 [==============================] - 27s 5s/step - loss: -131.6428 - accuracy: 0.0521 - val_loss: -380.1738 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/10\n",
      "6/6 [==============================] - 29s 5s/step - loss: -173.4831 - accuracy: 0.0521 - val_loss: -472.0008 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/10\n",
      "6/6 [==============================] - 34s 6s/step - loss: -206.2037 - accuracy: 0.0521 - val_loss: -568.1902 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/10\n",
      "6/6 [==============================] - 36s 6s/step - loss: -250.2173 - accuracy: 0.0521 - val_loss: -668.6026 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x249c7555d10>"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "epochs = 10\n",
    "batch_size = 32\n",
    "model.fit(data, labels, epochs=epochs, batch_size=batch_size, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 4s 543ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.041666666666666664"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(labels, y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
